{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Introduction to Bayesian Statistics\n",
    "Week 10 | Lesson 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "\n",
    "After this lesson, you will be able to:\n",
    "\n",
    "- Understand the building blocks of probability theory\n",
    "- Calculate joint probability\n",
    "- Derive and explain Bayes' theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's talk a little about basic probability concepts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There are three axioms of probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Nonnegativity**\n",
    "\n",
    "For any event $A$, the probability of the event must be greater than or equal to zero.\n",
    "\n",
    "### $$ 0 \\le P(A) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Unit measure**\n",
    "\n",
    "The probability of the entire sample space is 1.\n",
    "\n",
    "### $$ P(S) = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Additivity**\n",
    "\n",
    "For mutually exclusive, or in other words \"disjoint\" events $E$, the probability of any of the events occuring is equivalent to the sum of their probabilties.\n",
    "\n",
    "### $$ P\\left(\\cup_{i=1}^{\\infty}\\; E_i \\right) = \\sum_{i=1}^{\\infty} P(E_i) $$\n",
    "\n",
    "> Check: what's an example of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see this geometrically...\n",
    "<img src=\"./assets/images/disjoint.png\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## There are a few more key concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The probability of no event**\n",
    "\n",
    "The probability of the empty set, denoted $\\emptyset$, is zero.\n",
    "\n",
    "\n",
    "### $$ P\\left(\\emptyset \\right) = 0 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**The probability of A or B occuring (union)**\n",
    "\n",
    "The probability of event $A$ or event $B$ occuring is equivalent to the sum of their individual probabilities minus the intersection of their probabilities (the probability they both occur).\n",
    "\n",
    "### $$ P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can see this geometrically...\n",
    "\n",
    "<img src = \"./assets/images/union.png\" width = 800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Conditional probability**\n",
    "\n",
    "The probability of an event conditional on another event is written using a vertical bar between the two events. The probability of event $A$ occuring _given_ event $B$ occurs is calculated:\n",
    "\n",
    "### $$ P(A | B) = \\frac{P(A \\cap B)}{P(B)} $$\n",
    "\n",
    "Meaning the probability of both $A$ and $B$ occuring divided by the probability that $B$ occurs at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Joint probability**\n",
    "\n",
    "The joint probability of two events $A$ and $B$ is a reformulation of the above equation.\n",
    "\n",
    "### $$ P(A \\cap B) = P(A|B) \\; P(B) $$\n",
    "\n",
    "Verbally, if we want to know the probability that both $A$ and $B$ happen, we can multiply the probability that $B$ happens by the probability that $A$ happens given $B$ happens.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Joint probability**\n",
    "\n",
    "What if we assume that events A and B are independent?  What does that mean? And what impact does it have on the formula for the joint probability?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If A and B are independent, then $P(A|B) = P(A)$ so:\n",
    "\n",
    "### $$ P(A \\cap B) = P(A) \\; P(B) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OK we're ready for Bayes now!\n",
    "\n",
    "But first.... let's talk random variables.  \n",
    "\n",
    "What is a random variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Here's what the internet says...\n",
    "\n",
    "- A random variable is a set of possible values from a random experiment.\n",
    "\n",
    "- A quantity having a numerical value for each member of a group, especially one whose values occur according to a frequency distribution\n",
    "\n",
    "- A variable quantity whose value depends on possible outcomes\n",
    "\n",
    "- A random variable is a variable whose value is unknown or a function that assigns values to each of an experiment's outcomes.\n",
    "\n",
    "- A numerical characteristic that takes on different values due to chance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Types of random variables\n",
    "\n",
    "- discrete \n",
    "- continuous \n",
    "\n",
    "> What is an example of each?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete random variables\n",
    "\n",
    "We tend to find it easier to think about probability for discrete random variables.\n",
    "\n",
    "For example, what is the probability of rolling a 2 if you have a fair sided die?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Answer: 1/6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous random variables\n",
    "\n",
    "For continuous random variables, it's a little trickier.\n",
    "\n",
    "For example, what is the probability of a person being 6'2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Answer: 0\n",
    "\n",
    "Since the random variable can take any value between $0$ and $\\infty$, the probability of a given value is\n",
    "$$ 1 / \\infty$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Er... so now what?\n",
    "\n",
    "The probability of a continuous random variable being exactly a given number is 0.  But the probability of being in a given interval is non-zero.\n",
    "\n",
    "For example, the probability of a person being between 6' and 6'2 has a non-zero value.\n",
    "\n",
    "So how do we calculate that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## MATH\n",
    "\n",
    "...cue scary music..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probability density distribution\n",
    "\n",
    "\"A function of a continuous random variable, whose integral across an interval gives the probability that the value of the variable lies within the same interval.\" [wiki](https://en.wikipedia.org/wiki/Probability_density_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "<img src=\"./assets/images/norm.png\" width =600 align=\"center\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## OK, time for Bayes\n",
    "\n",
    "### Bayes Rule\n",
    "\n",
    "Bayes Rule relates the probability of $A$ given $B$ to the probability of $B$ given $A$. This rule is critical for performing statistical inference, as we shall see shortly. It is formulated as:\n",
    "\n",
    "### $$ P(A|B) = \\frac{P(B|A)\\;P(A)}{P(B)} $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An example from the first few weeks\n",
    "\n",
    "We were sitting in this room, and the firm alarm went off.  We all stopped momentarily, but didn't get up because we didn't think there was really a fire.  \n",
    "\n",
    "Why were we so sure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## BAYES!  \n",
    "\n",
    "(we do it instinctively!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's apply this to the fire alarm case\n",
    "\n",
    "### $$ P(fire|alarm) = \\frac{P(alarm|fire)\\;P(fire)}{P(alarm)} $$\n",
    "\n",
    "Let's put some numbers to this\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So based on our previous experiences, we have a belief about the probability of an event occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## We can apply this same concept to models!\n",
    "\n",
    "We'll do a basic introduction to this today, and then revisit tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Bayes' theorem in the context of statistical modeling\n",
    "\n",
    "\n",
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)}{P(\\;data\\;)} P\\left(\\;model\\;\\right)$$\n",
    "\n",
    "Or in plain english:\n",
    "\n",
    "**What is the probability of our model being true, given the data we have? This depends on the likelihood of the observed data given our model and the data itself, as well as our prior belief that this model is true.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Terminology**\n",
    "\n",
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)}{P(\\;data\\;)} P\\left(\\;model\\;\\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "$P\\left(\\;model\\;|\\;data\\;\\right)$ is the **posterior probability**\n",
    "\n",
    "$P\\left(\\;data\\;|\\;model\\;\\right)$ is the **likelihood,** which is the probability of what we observed  given our prior belief about the model. \n",
    "\n",
    "${P(\\;data\\;)}$ is the **marginal probability** of the observed data. This is also known as the **evidence** or the **normalization constant.**\n",
    "\n",
    "$P\\left(\\;model\\;\\right)$ is the **prior probability** belief. It is what you thought the model was before observing the events.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take a very simple example to illustrate the basics.  \n",
    "\n",
    "You have two coins in a bag.  One you know is fair, and one you know is biased.\n",
    "\n",
    "    coin FAIR has a 50% chance of flipping heads.\n",
    "    coin RIGGED has 99% chance of flipping heads.\n",
    "    \n",
    "Your friend chooses one of the two coins at random. He flips the coin and gets heads. \n",
    "\n",
    "What is the probability that the coin flipped was **FAIR**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $$P\\left(\\;model\\;|\\;data\\;\\right) = \\frac{P\\left(\\;data\\;|\\;model\\;\\right)}{P(\\;data\\;)} P\\left(\\;model\\;\\right)$$\n",
    "\n",
    "** The prior**\n",
    "\n",
    "Our \"models\" here are the two coins.  \n",
    "\n",
    "i.e., one is a model in which there is a 50% chance of getting heads, and one is a model in which there is a 99% chance of getting heads.\n",
    "\n",
    "Given that there are only two models, and we pick at random, \n",
    "\n",
    "$P(model) = 0.5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** The likelihood**\n",
    "\n",
    "Let's assume that we believe that we got the fair coin.  So if we got the fair coin, the likehlihood is:\n",
    "\n",
    "$$P(data|model) = 0.5$$\n",
    "\n",
    "because with the fair coin, we have a 50% chance of getting heads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**The evidence**\n",
    "\n",
    "The evidence is simply the probability of getting heads in one toss, regardless of which model we have (or in other words, the weighted average between the models).\n",
    "\n",
    "$$P(data) = 0.5*0.5 + 0.5 * 0.99 = 0.745$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.335570469799\n"
     ]
    }
   ],
   "source": [
    "# Our hypothesis is our belief that the coin flipped was fair before we saw the outcome. \n",
    "# 0.5 since he chose at random.\n",
    "hypothesis_fair = 0.5\n",
    "\n",
    "# probability that we would get heads given our hypothesis was true, that the coin is the fair one:\n",
    "prob_flip_given_fair = 0.5\n",
    "\n",
    "# total probability of getting heads:\n",
    "prob_heads = (0.745)\n",
    "\n",
    "# solve for the probability our hypothesis is true given the flip:\n",
    "hypothesis_true = (prob_flip_given_fair * hypothesis_fair) / prob_heads\n",
    "\n",
    "\n",
    "print hypothesis_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> Check what is this in plain English?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Based on what we know about probability, what is probabilty that the coin was in fact the biased one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Since we believe we can only have one of two models here, it is simply:\n",
    "\n",
    "$$ 1 - 0.3356 = 0.6644 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's do this on the board to prove it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## That was a preview to models with the Bayesian approach!  We'll come back to that tomorrow!  For now, to reinforce the idea of Bayes..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Monty Hall Problem (Let's Make a Deal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is a classic brain-teaser, based on a game show, that has a solution that often seems counter-intuitive.  You're going to use Bayes to solve it!\n",
    "\n",
    "Here are the rules of the game\n",
    "- There are three doors.  Behind one door is a brand-new car.  Behind each of the other two is a goat\n",
    "- The host asks you to pick a door.  Without revealing what's behind the door you picked, the host opens one of the other two doors and shows you a goat\n",
    "- Then you have a choice to make.  Stick with your original pick, or switch doors\n",
    "\n",
    "What should you do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CHANGE DOORS EVERY TIME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For the lab, your task is to prove this using Bayes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References and sources modeled off of:\n",
    "\n",
    "http://ipython-books.github.io/featured-07/\n",
    "\n",
    "http://stats.stackexchange.com/questions/31867/bayesian-vs-frequentist-interpretations-of-probability\n",
    "\n",
    "http://jakevdp.github.io/blog/2014/03/11/frequentism-and-bayesianism-a-practical-intro/\n",
    "\n",
    "https://simple.wikipedia.org/wiki/Bayes%27_theorem\n",
    "\n",
    "https://en.wikipedia.org/wiki/Central_limit_theorem\n",
    "\n",
    "http://www.cogsci.ucsd.edu/classes/SP07/COGS14/NOTES/binomial_ztest.pdf\n",
    "\n",
    "https://en.wikipedia.org/wiki/Prior_probability#Uninformative_priors\n",
    "\n",
    "https://arbital.com/p/bayes_rule/?l=1zq\n",
    "\n",
    "https://betterexplained.com/articles/an-intuitive-and-short-explanation-of-bayes-theorem/\n",
    "\n",
    "http://www.yudkowsky.net/rational/bayes/\n",
    "\n",
    "http://people.stern.nyu.edu/wgreene/MathStat/Notes-2-BayesianStatistics.pdf\n",
    "\n",
    "http://stats.stackexchange.com/questions/58564/help-me-understand-bayesian-prior-and-posterior-distributions\n",
    "\n",
    "http://pages.uoregon.edu/cfulton/posts/bernoulli_trials_bayesian.html\n",
    "\n",
    "http://chrisstrelioff.ws/sandbox/2014/12/11/inferring_probabilities_with_a_beta_prior_a_third_example_of_bayesian_calculations.html\n",
    "\n",
    "https://www.chrisstucchio.com/blog/2013/magic_of_conjugate_priors.html\n",
    "\n",
    "http://stats.stackexchange.com/questions/58564/help-me-understand-bayesian-prior-and-posterior-distributions\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
