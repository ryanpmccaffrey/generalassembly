{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Stats Review & Intro to SciPy\n",
    "Week 2 | Lesson 4.2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LEARNING OBJECTIVES\n",
    "*After this lesson, you will be able to:*\n",
    "\n",
    "- Explain t-testing and demonstrate it with scipy\n",
    "- Contrast t-testing with simulation solutions\n",
    "- Explain Type I and Type II errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### \"Bayesian\" vs. \"Frequentist\"?\n",
    "\n",
    "We will talk more about Bayesian stats later in the course; for now we are focused on Frequentist statistics.\n",
    "\n",
    "We assume that the data that we have observed is a sample from an underlying population, and that population has fixed (but unknown to us) parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Setting the Scene\n",
    "\n",
    "We want to make a statement about ALL data points (the population) based on a SAMPLE of data points, and describe our UNCERTAINTY about that statement.\n",
    "\n",
    "To do this, we:\n",
    "- make an assumption about the population (i.e., come up with a hypothesis)\n",
    "- we calculate the probability of seeing the data we've seen if this assumption were true\n",
    "- based on this probability, we are able to say something about whether we think our assumption / hypothesis is reasonable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Estimating the mean height of female professional athletes from a Frequentist approach...\n",
    "\n",
    "As a Frequentist I believe:\n",
    "\n",
    "- The mean height of the population of female professional athletes is an unknown but fixed, \"true\" value.\n",
    "- I have 100 data points.  My 100 data points are a random sample. That is to say, I have collected at random 100 heights from the population pool.\n",
    "- This random sampling procedure is considered infinitely repeatable. My inferences about height are based on the idea that this sample is just one of an infinite number of hypothetical population samples. \n",
    "- Each of the possible samples has a sample mean.  They may differ between samples, but the true value of height is fixed across all hypothetical samples.\n",
    "- There is a distribution of possible sample means given the true fixed value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**FREQUENTISTS** ask:\n",
    "$$P(\\text{data}\\;|\\;\\text{true mean})$$\n",
    "\n",
    "So, for example, what is the probability of our data given a true and fixed population mean?\n",
    "\n",
    "In other words, if I assume that the true population of female professional athletes  has a mean value of 5'11,  what is the probability of observing a mean height of, say, 5'9 in my sample?\n",
    "\n",
    "Based on this probability, what can I say about my sample / population?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ok, more hypothesis testing!\n",
    "\n",
    "Let's say we are testing a new drug.\n",
    "\n",
    "- We randomly select 50 people to be in the placebo control condition and 50 people to recieve the treatment.\n",
    "- Our sample is selected from the broader, unknown population pool.\n",
    "- In a parallel world we could have ended up with any random sample from the population pool of 100 people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "The null hypothesis is, in this example, that there is no difference between placebo and treatment.\n",
    "\n",
    "*H0: The measured difference is equal to zero.*\n",
    "\n",
    "The alternative hypothesis is the other possible outcome of the experiment: the difference between the placebo and the treatment is real.\n",
    "\n",
    "*H1: The measured difference is not zero.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Say in our experiment we follow-up with the experimental and control groups:\n",
    "- 5 out of 50 patients in the control group indicate that their symptoms are better\n",
    "- 7 out of 50 patients in the experimental group indicate that their symptoms are better\n",
    "\n",
    "So does the drug work?  Is this enough to make a recommendation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Enter the p-value!\n",
    "\n",
    "The p-value is the probability that, GIVEN THE NULL HYPOTHESIS IS TRUE, we would have sampled the current set of data.\n",
    "\n",
    "We saw 10% improvement rate in placebo group, and 14% improvement rate in drug group.\n",
    "\n",
    "So, for this example, the *p-value* it is the probability that even if there is in fact no effect (i.e. the  means of the two underlying populations are the same), that we might see a difference of 4% or MORE simply owing to the random sampling (i.e. *just by chance!*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do we do with the p-value?\n",
    "\n",
    "Let's say the p-value here is 10%.  This means that if we were to repeat this experiment, 1 in 10 times we would see a difference of at least 4% just by chance.  \n",
    "\n",
    "Does that mean this finding is significant?  What can we say about our null hypothesis?\n",
    "\n",
    "Typically we pick a threshold (often 5%), below which we say \"if our null hypothesis were true, the probability of our seeing the data that we saw is so unlikely, that we no longer believe our null to be true.\"\n",
    "\n",
    "But here, the p-value is above 5%, so we fail to reject our null.\n",
    "\n",
    "So we have no reason to think that the measured difference is not actually zero, or, in other words,  that the drug has an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sidenote:\n",
    "\n",
    "\n",
    "Strictly speaking, we only ever reject the null, or fail to reject the null.\n",
    "\n",
    "Rejecting the null is not the same as accepting the alternative!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Great!  But how do I calculate this p-value?\n",
    "\n",
    "We can do this parametrically or computationally.\n",
    "\n",
    "Assuming we take the parametric approach, we need a few building blocks...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Law of large numbers (Probability Theory)\n",
    "\n",
    " \n",
    "If you perform the same experiment a large number of times, the average of the results should approach the expected value.\n",
    "\n",
    "So if I repeatedly take samples from a population, and calculate the sample mean each time, the average of these sample means should equal the population mean.\n",
    "\n",
    "\n",
    "This means that for sufficiently large N, $\\bar{Y}\\ -\\ \\mu$ is ~ 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central limit theorem\n",
    "\n",
    "- If you sample from an underlying population with mean $\\mu$ and variance $\\sigma^2$, then when *n* is large, sample mean $\\hat{\\mu}$ is approximately normally distributed with mean $\\mu$ and variance $\\frac{\\sigma^2}{n}$.\n",
    "- If the sample sizes are large enough, this is true regardless of the underlying distribution!\n",
    "- So what? \n",
    "Well, this allows us to assume that some random variables are normally distributed, and to make inferences about the likelihood of observations drawn from that distribution. For instance, it implies:\n",
    "\n",
    "$$\\frac{\\hat{\\mu}\\ -\\ \\mu}{\\sigma/\\sqrt{n}}\\ \\sim \\ N(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## T-tests revisited\n",
    "\n",
    "Does $\\frac{\\hat{\\mu}\\ -\\ \\mu}{\\sigma/\\sqrt{n}}$ look familiar? If we use the sample standard deviation in the denominator, that's the t-statistic!\n",
    "\n",
    "$$\\frac{\\hat{\\mu}\\ -\\ \\mu}{s/\\sqrt{n}}$$\n",
    "\n",
    "And if n is large, then the value of the t-statistic is approximately normally distributed. (If n is small and the sample observations are normally distributed, then it has a t-distribution.)\n",
    "\n",
    "$\\frac{s}{\\sqrt{n}}$ is also called the standard error, $s.e.(\\hat{\\mu})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## P-values and hypothesis testing, revisited\n",
    "\n",
    "So what if the t statistic is normally distributed?\n",
    "\n",
    "Well, then we can calculate the probability of having observed that t-statistic.  \n",
    "\n",
    "Or, in terms of hypothesis testing for the difference of means (drug treatment), we can calculate the probability of having observed a difference as large (or larger) than we did, if there is in fact no difference (i.e. if our null hypothesis is true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How do we calculate it?\n",
    "\n",
    "\n",
    "![](./norm_dist_probs.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypothesis testing with t-tests, an example\n",
    "\n",
    "Let's say 1165 bootcamp applicants take a GA admissions test in 2017, with an average score of 60.86 and a standard deviation of 8.02. The expected score for all bootcamp applicants is 59. Do GA applicants have the same expected score as the underlying population?\n",
    "\n",
    "The sample standard deviation *s* is 8.02.\n",
    "\n",
    "Standard error of the estimate is then $se(\\hat{\\mu}) = \\frac{s}{\\sqrt{n}} = \\frac{8.02}{\\sqrt{1165}} = 0.235$\n",
    "\n",
    "> What are our null and alternative hypotheses?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$$H_0: \\mu = 59$$\n",
    "$$H_a: \\mu \\neq 59$$\n",
    "\n",
    "\n",
    "\n",
    "Under $H_0,\\ t = \\frac{\\hat{\\mu} - 59}{se(\\hat{\\mu})}$ is approximately normally distributed with N(0,1). If t falls far on the tail, the p-value is low and we'll reject $H_0$.\n",
    "\n",
    "Calculate the t-statistic and [look up its p-value](https://graphpad.com/quickcalcs/PValue1.cfm]).\n",
    "\n",
    "(for degrees of freedom, use n-1, where n is the size of the sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$t = \\frac{60.86 - 59}{0.2350} = 7.915$$\n",
    "\n",
    "pvalue <0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Again, but now with scipy ('skippy'?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.05037070851 61.1582143415\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "np.random.seed(7654567)  # fix seed to get the same result\n",
    "rvs = stats.norm.rvs(loc=60.86, scale=8.02, size=(1165))\n",
    "\n",
    "# Note that the mean and std of our generated data aren't precisely the \n",
    "#same.\n",
    "print np.std(rvs), np.mean(rvs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which scipy function to use?  \n",
    "\n",
    "A few common t-tests include:\n",
    "- One-sample t-test. Used to determine whether a hypothesized population\n",
    "    mean differs significantly from an observed sample mean.\n",
    "- Two-sample t-test. Used to determine whether the difference between samples means differs significantly from the              hypothesized difference between population means.\n",
    "- Paired t-test. Used to test the significance of the difference\n",
    "    between paired means.\n",
    "\n",
    "Scipy has methods for all of these, and more. Which one do we want?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Also, tails?  \n",
    "\n",
    "<br>\n",
    "\n",
    "#### One tailed test\n",
    "I care about direction (e.g. the mean for these students is *higher* than the population mean)\n",
    "<br><br>\n",
    "#### Two tailed test\n",
    "I don't care about direction (e.g. the mean for these students is *different* to the population mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_1sampResult(statistic=9.1465051826423593, pvalue=2.5558469858139369e-19)\n"
     ]
    }
   ],
   "source": [
    "# Test if mean of random sample is equal to true mean\n",
    "\n",
    "print stats.ttest_1samp(rvs,59.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Do we reject the hypothesis?  \n",
    "\n",
    "Yes!\n",
    "\n",
    "So based on the data we collected, we do not believe that the mean for the students who took the test in March is the same as the mean for students generally.\n",
    "\n",
    ">Check:\n",
    "Did scipy do a one tailed or two tailed ttest?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you want to to convert a p-value from a two-tailed test to the p-value for the equivalent one-tailed test, we can simply divide by 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: classic t-tests (30 minutes)\n",
    "\n",
    "In pairs or trios, look at the SAT test data from Project 1. (We'll assume it's a sample of results, rather than the population results.) Together, form null and alternative hypotheses about some of the scores. \n",
    "(E.g., H0: the mean difference between states' verbal and math scores is 0)\n",
    "\n",
    "Choose a significance level and conduct an appropriate t-test.  Repeat for a few different hypotheses.  Be prepared to describe your findings with another group!  Think about how you might describe these findings to someone who hasn't studied statistics.\n",
    "\n",
    "- [t-tests](http://iaingallagher.tumblr.com/post/50980987285/t-tests-in-python)\n",
    "- [t distribution](http://stattrek.com/probability-distributions/t-distribution.aspx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Significance levels, Type I and Type II errors\n",
    "\n",
    "Type I errors occur when the researcher rejects a null hypothesis when it is actually true. The probability of committing a Type I error is called the significance level, often denoted $\\alpha$.\n",
    "\n",
    "$$\\alpha\\ =\\ P(Reject\\ H_0\\ |\\ H_0\\ is\\ true) = P(Type\\ I\\ error)$$\n",
    "\n",
    "So, if our threshold level / significance level were 5%, if we repeated the experiment 20 times, just by chance, we might reject the null hypothesis once, even if it is in fact true.\n",
    "\n",
    "Also... see [p-hacking](https://projects.fivethirtyeight.com/p-hacking/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A Type II error occurs when the researcher wrongly accepts a null hypothesis that is false.  The probability of committing a Type II error is often denoted by $\\beta$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\\beta\\ =\\ P(Not rejecting \\ H_0\\ |\\ H_a\\ is\\ true) = P(Type\\ II\\ error)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"t-testing\"></a>\n",
    "## Demo/Guided Practice: computational approaches (10 minutes)\n",
    "\n",
    "Now that computational power is cheap and available (and you know Python!), we have an alternative way of approaching these questions: we can iteratively calculate the probability of observing some result.  We can simulate a repeated experiment!\n",
    "\n",
    "For example:\n",
    "\n",
    "```Python\n",
    "# Simulating a binomial variable (e.g. seeing heads in 20 out of 30 coin flips )\n",
    "m = 0\n",
    "for i in range(10000):\n",
    "    trials = np.random.randint(2, size = 30)\n",
    "    if (trials.sum() >= 20):\n",
    "        m += 1\n",
    "p = m / 10000.0\n",
    "p\n",
    "```\n",
    "\n",
    "> Check: what is this doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0492"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = 0\n",
    "for i in range(10000):\n",
    "    trials = np.random.randint(2, size = 30)\n",
    "    if (trials.sum() >= 20):\n",
    "        m += 1\n",
    "p = m / 10000.0\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This was an example if **simulating** your experiment -- you can do this if you have an a priori model of what happens.\n",
    "\n",
    "If you don't have an a priori model, another option is **shuffling** results:\n",
    "\n",
    "(Example from: http://cs.nyu.edu/shasha/papers/StatisticsIsEasyExcerpt.html)\n",
    "\n",
    "\n",
    "Placebo: 54 51 58 44 55 52 42 47 58 46\n",
    "\n",
    "Drug: 54 73 53 70 73 68 52 65 65\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\"As you can see, the drug seems more effective on the average (the average measured improvement is 63.7 for the drug and 50.7 for the placebo). But is this difference in the average real? Formula-based statistics would use a t-test which entails certain assumptions about normality and variance, but we are going to look just at the samples themselves and shuffle the labels.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What this means can be illustrated as follows. We put all the people in a table having two columns value and label (P for placebo and D for drug).\n",
    "\n",
    "| value | label |\n",
    "|:-:|---|\n",
    "|54\t| P |\n",
    "|51\t| P |\n",
    "|58\t| P |\n",
    "|44\t| P |\n",
    "|55\t| P |\n",
    "|52\t| P |\n",
    "|42\t| P |\n",
    "|47\t| P |\n",
    "|58\t| P |\n",
    "|46\t| P |\n",
    "|54\t| D |\n",
    "|73\t| D |\n",
    "|53\t| D |\n",
    "|70\t| D |\n",
    "|73\t| D |\n",
    "|68\t| D |\n",
    "|52\t| D |\n",
    "|65\t| D |\n",
    "|65\t| D |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Shuffling the labels means that we will take the Ps and Ds and randomly distribute them among the patients. \n",
    "\n",
    "This might give:\n",
    "\n",
    "| value | label |\n",
    "|:-:|---|\n",
    "|54\t| P \n",
    "|51\t| P\n",
    "|58\t| D\n",
    "|44\t| P\n",
    "|55\t| P\n",
    "|52\t| D\n",
    "|42\t| D\n",
    "|47\t| D\n",
    "|58\t| D\n",
    "|46\t| D\n",
    "|54\t| P\n",
    "|73\t| P\n",
    "|53\t| P\n",
    "|70\t| D\n",
    "|73\t| P\n",
    "|68\t| P\n",
    "|52\t| D\n",
    "|65\t| P\n",
    "|65\t| D\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can then look at the difference in the average P value vs. the average D value here. We get an average of 59.0 for P and 54.4 for D. We repeat this shuffle-then-measure procedure 10,000 times and ask what fraction of time we get a difference between drug and placebo greater than or equal to the measured difference of 63.7 - 50.7 = 13. The answer in this case is under 0.001.\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"ind-practice\"></a>\n",
    "## Independent Practice: finding probabilities computationally (45 minutes)\n",
    "\n",
    "In pairs or trios, design and code a computational way of finding the probability of rolling a 6 at least one-third of the time on a fair die.\n",
    "\n",
    "Got it? Now try finding the probability of seeing a difference of at least 0.686 between the mean verbal and math scores in your SAT dataset, assuming there is, in truth, no difference between these means.  Try shuffling!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a name=\"conclusion\"></a>\n",
    "## Conclusion (5 mins)\n",
    "\n",
    "- We make trade-offs between risking Type I and Type II errors\n",
    "- There are varieties of t-tests, and scipy methods for conducting them\n",
    "- Simulations / computation strategies are an alternative to parametric statistical inference"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
